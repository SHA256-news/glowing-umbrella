name: Publish Article

'on':
  schedule:
    # Run every day at 9 AM UTC
    - cron: '0 9 * * *'
  workflow_dispatch:
    inputs:
      max_articles:
        description: 'Maximum number of articles to fetch'
        required: false
        default: '5'
        type: string
      days_back:
        description: 'Number of days back to search'
        required: false
        default: '1'  # Reduced from 7 to 1 for much better performance
        type: string
      test_mode:
        description: 'Run in test mode with sample data (no API calls)'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.12'

jobs:
  fetch-and-generate:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Fetch Bitcoin mining news URIs
        id: fetch_news
        env:
          EVENTREGISTRY_API_KEY: ${{ secrets.EVENTREGISTRY_API_KEY }}
          MAX_ARTICLES: "5"
          MINUTES_BACK: "6"
        run: |
          set -euo pipefail

          max_articles="${MAX_ARTICLES:-5}"
          minutes_back="${MINUTES_BACK:-6}"

          echo "Attempting fast fetch..."
          python scripts/fetch_news.py \
            --max-articles "$max_articles" \
            --minutes-back "$minutes_back" \
            --output-format uris \
            --fast-mode > news_uris.txt || true

          if [ ! -s news_uris.txt ]; then
            echo "Fast mode returned no data. Trying smaller windows with retries..."
            for minutes in 60 30 15 5 2; do
              echo "Trying ${minutes} minute window..."
              python scripts/fetch_news.py \
                --max-articles "$max_articles" \
                --minutes-back "$minutes" \
                --output-format uris \
                --timeout 45 \
                --retries 3 > news_uris.txt && break || true
            done
          fi

          # Test mode fallback removed - workflow should fail if no real news URIs available

          if [ ! -s news_uris.txt ]; then
            echo "No news articles found and fallback disabled. Exiting."
            exit 1
          fi

          # Get the first URI for article generation
          first_uri=$(head -n 1 news_uris.txt)
          echo "first_uri=$first_uri" >> $GITHUB_OUTPUT

          echo "Found $(wc -l < news_uris.txt) news articles"
          echo "Processing first article: $first_uri"
      - name: Generate article
        id: generate_article
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          EVENTREGISTRY_API_KEY: ${{ secrets.EVENTREGISTRY_API_KEY }}
          ENABLE_PLACEHOLDER: "false"
        run: |
          if [ -z "${{ steps.fetch_news.outputs.first_uri }}" ]; then
            echo "No news URI available for article generation."
            exit 1
          fi

          echo "Generating article for URI: ${{ steps.fetch_news.outputs.first_uri }}"
          test_mode="${{ github.event.inputs.test_mode || 'false' }}"

          if [ "$test_mode" = "true" ]; then
            echo "ðŸ§ª Using test mode for article generation"
            # Create a dummy events.json with test URI for test mode
            echo '{"event_uris": ["test-mode-sample"], "updated_at": "'$(date -Iseconds)'", "total_events": 1}' > events.json
            python scripts/generate_article.py --test-mode
          else
          # Create events.json from the fetched URIs
          echo "Creating events.json from fetched news URIs..."
          python -c "
          import json
          from datetime import datetime
          import sys

          # Read URIs from news_uris.txt
          try:
              with open('news_uris.txt', 'r') as f:
                  uris = [line.strip() for line in f if line.strip()]
              
              if not uris:
                  print('No URIs found in news_uris.txt')
                  sys.exit(1)
              
              # Create events.json in the format expected by generate_article.py
              events_data = {
                  'event_uris': uris,
                  'updated_at': datetime.now().isoformat(),
                  'total_events': len(uris)
              }
              
              with open('events.json', 'w') as f:
                  json.dump(events_data, f, indent=2)
              
              print(f'Created events.json with {len(uris)} URIs')
          except FileNotFoundError:
              print('news_uris.txt not found')
              sys.exit(1)
          except Exception as e:
              print(f'Error creating events.json: {e}')
              sys.exit(1)
          "
            python scripts/generate_article.py
          fi

          # Verify the article was generated and copy to expected location
          if [ -n "$(ls -A articles/ 2>/dev/null)" ]; then
            # Find the most recently created article file
            latest_article=$(ls -t articles/*.json 2>/dev/null | head -n 1)
            if [ -n "$latest_article" ]; then
              cp "$latest_article" "generated_article.json"
              echo "Article generated successfully: $latest_article -> generated_article.json"
            else
              echo "Failed to generate article - no files in articles directory."
              exit 1
            fi
          elif [ -f "generated_article.json" ]; then
            echo "Placeholder article generated directly"
          else
            echo "Failed to generate article."
            exit 1
          fi

          # Extract headline for summary
          headline=$(python -c "import json; data=json.load(open('generated_article.json')); print(data.get('headline', 'Bitcoin Mining News'))")
          echo "article_headline=$headline" >> $GITHUB_OUTPUT

      - name: Create GitHub Issue with Article
        if: success()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read the generated article
            const articleData = JSON.parse(fs.readFileSync('generated_article.json', 'utf8'));

            // Create issue body
            const issueBody = `# ${articleData.headline}

            ${articleData.subtitle || ''}

            ## Article Content

            ${articleData.content}

            ## Key Points

            ${articleData.key_points ? articleData.key_points.map(point => `- ${point}`).join('\n') : 'N/A'}

            ## Metadata

            - **Generated At:** ${articleData.generated_at}
            - **Source Event URI:** ${articleData.source_event_uri}
            - **Model Used:** ${articleData.model_used}
            - **Tags:** ${articleData.tags ? articleData.tags.join(', ') : 'N/A'}

            ---

            *This article was automatically generated by the news pipeline.*`;

            // Create the issue with safe labels only
            const { data: issue } = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ðŸ“° ${articleData.headline}`,
              body: issueBody,
              labels: ['automated-article']
            });

            console.log(`Created issue #${issue.number}: ${issue.title}`);

      - name: Upload article artifact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: generated-article-${{ github.run_number }}
          path: |
            generated_article.json
            news_uris.txt
          retention-days: 30

      - name: Trigger Twitter posting workflow
        if: success()
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'post_to_twitter.yml',
              ref: context.ref,
              inputs: {
                article_run_number: '${{ github.run_number }}'
              }
            });

            console.log('Triggered Twitter posting workflow');
