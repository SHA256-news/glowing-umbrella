name: Publish Article

'on':
  schedule:
    # Run every day at 9 AM UTC
    - cron: '0 9 * * *'
  workflow_dispatch:
    inputs:
      max_articles:
        description: 'Maximum number of articles to fetch'
        required: false
        default: '5'
        type: string
      days_back:
        description: 'Number of days back to search'
        required: false
        default: '1'  # Reduced from 7 to 1 for much better performance
        type: string
      test_mode:
        description: 'Run in test mode with sample data (no API calls)'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.12'

jobs:
  fetch-and-generate:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Fetch Bitcoin mining news URIs
        id: fetch_news
        env:
          EVENTREGISTRY_API_KEY: ${{ secrets.EVENTREGISTRY_API_KEY }}
        run: |
          set -euo pipefail

          # Get parameters from workflow inputs or defaults
          max_articles="${{ github.event.inputs.max_articles || '5' }}"
          days_back="${{ github.event.inputs.days_back || '1' }}"
          
          # Convert days to minutes for the script
          minutes_back=$((days_back * 24 * 60))

          # Convert days to minutes for the script
          minutes_back=$((days_back * 24 * 60))

          echo "Fetching news: max_articles=$max_articles, days_back=$days_back (${minutes_back} minutes)"

          echo "Attempting fast fetch with ${minutes_back} minute window..."
          python scripts/fetch_news.py \
            --max-articles "$max_articles" \
            --minutes-back "$minutes_back" \
            --output-format uris \
            --fast-mode > news_uris.txt || true

          if [ ! -s news_uris.txt ]; then
            echo "Fast mode returned no data. Trying progressive fallback with smaller windows..."
            # Progressive fallback with smaller time windows
            for hours in 12 6 3 1; do
              fallback_minutes=$((hours * 60))
              echo "Trying ${hours} hour window (${fallback_minutes} minutes)..."
              python scripts/fetch_news.py \
                --max-articles "$max_articles" \
                --minutes-back "$fallback_minutes" \
                --output-format uris \
                --timeout 45 \
                --retries 3 > news_uris.txt && break || true
            done
          fi

          # Test mode fallback removed - workflow should fail if no real news URIs available

          if [ ! -s news_uris.txt ]; then
            echo "No news articles found and fallback disabled. Exiting."
            exit 1
          fi

          # Get the first URI for article generation
          first_uri=$(head -n 1 news_uris.txt)
          echo "first_uri=$first_uri" >> $GITHUB_OUTPUT

          echo "Found $(wc -l < news_uris.txt) news articles"
          echo "Processing first article: $first_uri"
      - name: Generate article
        id: generate_article
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          EVENTREGISTRY_API_KEY: ${{ secrets.EVENTREGISTRY_API_KEY }}
          ENABLE_PLACEHOLDER: "false"
        run: |
          if [ -z "${{ steps.fetch_news.outputs.first_uri }}" ]; then
            echo "No news URI available for article generation."
            exit 1
          fi

          echo "Generating article for URI: ${{ steps.fetch_news.outputs.first_uri }}"
          test_mode="${{ github.event.inputs.test_mode || 'false' }}"

          if [ "$test_mode" = "true" ]; then
            echo "ðŸ§ª Using test mode for article generation"
            # Create a dummy events.json with test URI for test mode
            echo '{"event_uris": ["test-mode-sample"], "updated_at": "'$(date -Iseconds)'", "total_events": 1}' > events.json
            python scripts/generate_article.py --test-mode
          else
          # Create events.json from the fetched URIs
          echo "Creating events.json from fetched news URIs..."
          python -c "
          import json
          from datetime import datetime
          import sys

          # Read URIs from news_uris.txt
          try:
              with open('news_uris.txt', 'r') as f:
                  uris = [line.strip() for line in f if line.strip()]
              
              if not uris:
                  print('No URIs found in news_uris.txt')
                  sys.exit(1)
              
              # Create events.json in the format expected by generate_article.py
              events_data = {
                  'event_uris': uris,
                  'updated_at': datetime.now().isoformat(),
                  'total_events': len(uris)
              }
              
              with open('events.json', 'w') as f:
                  json.dump(events_data, f, indent=2)
              
              print(f'Created events.json with {len(uris)} URIs')
          except FileNotFoundError:
              print('news_uris.txt not found')
              sys.exit(1)
          except Exception as e:
              print(f'Error creating events.json: {e}')
              sys.exit(1)
          "
            python scripts/generate_article.py
          fi

          # Verify the article was generated and copy to expected location
          if [ -n "$(ls -A articles/ 2>/dev/null)" ]; then
            # Find the most recently created article file
            latest_article=$(ls -t articles/*.json 2>/dev/null | head -n 1)
            if [ -n "$latest_article" ]; then
              cp "$latest_article" "generated_article.json"
              echo "Article generated successfully: $latest_article -> generated_article.json"
            else
              echo "Failed to generate article - no files in articles directory."
              exit 1
            fi
          elif [ -f "generated_article.json" ]; then
            echo "Placeholder article generated directly"
          else
            echo "Failed to generate article."
            exit 1
          fi

          # Extract headline for summary
          headline=$(python -c "import json; data=json.load(open('generated_article.json')); print(data.get('headline', 'Bitcoin Mining News'))")
          echo "article_headline=$headline" >> $GITHUB_OUTPUT
          echo "article_generated=true" >> $GITHUB_OUTPUT

      - name: Create GitHub Issue with Article
        if: success()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            try {
              // Read the generated article
              const articleData = JSON.parse(fs.readFileSync('generated_article.json', 'utf8'));

              // Create issue body with all available fields
              let issueBody = `# ${articleData.headline || 'Bitcoin Mining News'}

            ${articleData.subtitle || ''}

            ## Article Content

            ${articleData.content || articleData.body || 'No content available'}`;

              // Add key points if available
              if (articleData.key_points && Array.isArray(articleData.key_points)) {
                issueBody += `

            ## Key Points

            ${articleData.key_points.map(point => `- ${point}`).join('\n')}`;
              }

              // Add AI-generated reflection questions if available
              if (articleData.reflection_questions && Array.isArray(articleData.reflection_questions)) {
                issueBody += `

            ## Reflection Questions

            ${articleData.reflection_questions.map(q => `- ${q}`).join('\n')}`;
              }

              // Add calls to action if available
              if (articleData.calls_to_action && Array.isArray(articleData.calls_to_action)) {
                issueBody += `

            ## Calls to Action

            ${articleData.calls_to_action.map(cta => `- ${cta}`).join('\n')}`;
              }

              // Add metadata section
              issueBody += `

            ## Metadata

            - **Generated At:** ${articleData.generated_at || 'N/A'}
            - **Source Event URI:** ${articleData.source_event_uri || 'N/A'}
            - **Model Used:** ${articleData.model_used || 'N/A'}
            - **Tags:** ${articleData.tags ? articleData.tags.join(', ') : 'N/A'}`;

              issueBody += `

            ---

            *This article was automatically generated by the news pipeline.*`;

              // Create the issue with safe labels only
              const { data: issue } = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `ðŸ“° ${articleData.headline || 'Bitcoin Mining News'}`,
                body: issueBody,
                labels: ['automated-article']
              });

              console.log(`Created issue #${issue.number}: ${issue.title}`);
              
            } catch (error) {
              console.error('Error creating GitHub issue:', error.message);
              // Don't fail the entire workflow if issue creation fails
              console.log('Continuing workflow despite issue creation failure');
            }

      - name: Upload article artifact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: generated-article-${{ github.run_number }}
          path: |
            generated_article.json
            news_uris.txt
          retention-days: 30

      - name: Trigger Twitter posting workflow
        if: steps.generate_article.outputs.article_generated == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            try {
              await github.rest.actions.createWorkflowDispatch({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'post_to_twitter.yml',
                ref: context.ref,
                inputs: {
                  article_run_number: '${{ github.run_number }}'
                }
              });

              console.log('Successfully triggered Twitter posting workflow with run number: ${{ github.run_number }}');
            } catch (error) {
              console.error('Error triggering Twitter workflow:', error.message);
              // Don't fail the entire workflow if Twitter trigger fails
              console.log('Article generation completed successfully despite Twitter trigger failure');
            }
